{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładowanie danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "\n",
    "train_size = int(0.9 * len(trainset))\n",
    "val_size = len(trainset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(trainset, [train_size, val_size])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "valloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokazanie obrazków:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model i jego warstwy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool2 = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(16 * 8 * 8, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pokazanie ilości parametrów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ukazanie modelu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 136886\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "model = Model()\n",
    "print(model)\n",
    "print(f\"Liczba parametrów modelu: {count_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka [1/10], Strata treningowa: 1.5074900605486499\n",
      "Strata walidacyjna po epoce: 1.2907277737855911\n",
      "Epoka [2/10], Strata treningowa: 1.2050255196005106\n",
      "Epoka [3/10], Strata treningowa: 1.0681614307314158\n",
      "Epoka [4/10], Strata treningowa: 0.9763941591480954\n",
      "Strata walidacyjna po epoce: 1.0724667567282915\n",
      "Epoka [5/10], Strata treningowa: 0.9005059866003589\n",
      "Epoka [6/10], Strata treningowa: 0.8375562121129284\n",
      "Epoka [7/10], Strata treningowa: 0.7838265806510992\n",
      "Strata walidacyjna po epoce: 1.1254453417984769\n",
      "Epoka [8/10], Strata treningowa: 0.7305191632421687\n",
      "Epoka [9/10], Strata treningowa: 0.6924083313173045\n",
      "Epoka [10/10], Strata treningowa: 0.6489842686807504\n",
      "Strata walidacyjna po epoce: 1.223310985195823\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6670777777777778\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 10\n",
    "total_correct = 0\n",
    "total_samples = 0 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        output_loss = loss(output, labels)\n",
    "        output_loss.backward()  \n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        running_loss += output_loss.item()\n",
    "\n",
    "    print(f'Epoka [{epoch+1}/{num_epochs}], Strata treningowa: {running_loss/len(trainloader)}')\n",
    "\n",
    "    if (epoch % 3 == 0):\n",
    "        model.eval()\n",
    "        validation_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_images, val_labels in valloader:\n",
    "                val_output = model(val_images)\n",
    "                val_loss = loss(val_output, val_labels)\n",
    "                validation_loss += val_loss.item()\n",
    "\n",
    "        print(f'Strata walidacyjna po epoce: {validation_loss/len(valloader)}')\n",
    "        model.train()\n",
    "\n",
    "print(f'\\nWynik dokładności dla mojego modelu dla danych treningowych: {total_correct / total_samples}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla zbioru danych testowych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6342\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_samples = 0 \n",
    "\n",
    "for images, labels in testloader:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(images)\n",
    "    optimizer.step()\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    correct = (predicted == labels).sum().item()\n",
    "    test_correct += correct\n",
    "    test_samples += labels.size(0)\n",
    "\n",
    "\n",
    "print(f'\\nWynik dokładności dla mojego modelu dla danych testowych: {test_correct / test_samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametryzowalny model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Custom(nn.Module):\n",
    "    def __init__(self, layers, input_size=(32, 32)) -> None:\n",
    "        super(Model_Custom, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(layers[i][\"entry\"], layers[i][\"out\"], kernel_size=layers[i][\"kernel_size\"], stride=1, padding=2) for i in range(len(layers))])\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = None\n",
    "        # final_size = self._calculate_output_size(input_size[0], len(layers), layers)\n",
    "        # self.fc1 = nn.Linear(final_size * final_size * layers[-1][\"out\"], 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc_last = nn.Linear(84, 10)\n",
    "\n",
    "    def _calculate_output_size(self, input_size, n_layers, layers):\n",
    "        size = input_size\n",
    "        for i in range(n_layers):\n",
    "            size = (size + 2 * 2 - layers[i][\"kernel_size\"]) // 1 + 1\n",
    "            size = size // 2\n",
    "        return size\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(conv(x))\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        if self.fc1 is None:\n",
    "            in_features = x.size(1)\n",
    "            self.fc1 = nn.Linear(in_features, 120)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc_last(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customizowalny model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_net(lerning_late, layers, num_epochs):\n",
    "    model = Model_Custom(layers)\n",
    "    print(model)\n",
    "    print(f\"Liczba parametrów modelu: {count_parameters(model)}\")\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lerning_late)\n",
    "    total_correct = 0\n",
    "    total_samples = 0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            output_loss = loss(output, labels)\n",
    "            output_loss.backward()  \n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            running_loss += output_loss.item()\n",
    "\n",
    "        print(f'Epoka [{epoch+1}/{num_epochs}], Strata treningowa: {running_loss/len(trainloader)}')\n",
    "\n",
    "        if (epoch % 3 == 0):\n",
    "            model.eval()\n",
    "            validation_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_labels in valloader:\n",
    "                    val_output = model(val_images)\n",
    "                    val_loss = loss(val_output, val_labels)\n",
    "                    validation_loss += val_loss.item()\n",
    "\n",
    "            print(f'Strata walidacyjna po epoce: {validation_loss/len(valloader)}')\n",
    "            model.train()\n",
    "\n",
    "    print(f'\\nWynik dokładności dla mojego modelu dla danych treningowych: {total_correct / total_samples}')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_correct = 0\n",
    "    test_samples = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            test_correct += correct\n",
    "            test_samples += labels.size(0)\n",
    "\n",
    "    return test_correct / test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wywołanie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 13886\n",
      "Epoka [1/10], Strata treningowa: 1.6325626681804657\n",
      "Strata walidacyjna po epoce: 1.5027908665180207\n",
      "Epoka [2/10], Strata treningowa: 1.4289755011532042\n",
      "Epoka [3/10], Strata treningowa: 1.3545746428926786\n",
      "Epoka [4/10], Strata treningowa: 1.3102068643715648\n",
      "Strata walidacyjna po epoce: 1.3624903577983378\n",
      "Epoka [5/10], Strata treningowa: 1.2704350065979693\n",
      "Epoka [6/10], Strata treningowa: 1.2421796751028962\n",
      "Epoka [7/10], Strata treningowa: 1.2168171568140387\n",
      "Strata walidacyjna po epoce: 1.3252484933674336\n",
      "Epoka [8/10], Strata treningowa: 1.1970571238186625\n",
      "Epoka [9/10], Strata treningowa: 1.181119612658686\n",
      "Epoka [10/10], Strata treningowa: 1.1690153483678898\n",
      "Strata walidacyjna po epoce: 1.3178440434157848\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5312866666666667\n",
      "\n",
      "Wynik dokładności dla mojego modelu z customowymi parametrami dla danych testowych: 0.5502\n"
     ]
    }
   ],
   "source": [
    "layers = [\n",
    "    {\"entry\": 3, \"out\": 6, \"kernel_size\": 5},\n",
    "    {\"entry\": 6, \"out\": 16, \"kernel_size\": 5}\n",
    "]\n",
    "\n",
    "accaccuracy = custom_net(0.001, layers, 10)\n",
    "\n",
    "print(f'\\nWynik dokładności dla mojego modelu z customowymi parametrami dla danych testowych: {accaccuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Szukanie hiperparametrów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    conv_out = trial.suggest_int('conv_out', 16, 128, step=16)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 1, 5, step=2)\n",
    "\n",
    "    layers = [\n",
    "        {\"entry\": 3, \"out\": conv_out, \"kernel_size\": kernel_size}\n",
    "    ]\n",
    "    for _ in range(n_layers - 1):\n",
    "        layers.append({\"entry\": conv_out, \"out\": conv_out, \"kernel_size\": kernel_size})\n",
    "\n",
    "    accuracy = custom_net(lr, layers, num_epochs=10)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 14:29:46,439] A new study created in memory with name: no-name-d53ce513-cfbf-4c67-a744-6b97a33f9172\n",
      "C:\\Users\\Mateusz\\AppData\\Local\\Temp\\ipykernel_3548\\405360016.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 240166\n",
      "Epoka [1/10], Strata treningowa: 1.7454734951814015\n",
      "Strata walidacyjna po epoce: 1.5694284559488296\n",
      "Epoka [2/10], Strata treningowa: 1.4674640503883363\n",
      "Epoka [3/10], Strata treningowa: 1.3445630356642935\n",
      "Epoka [4/10], Strata treningowa: 1.2606209529088603\n",
      "Strata walidacyjna po epoce: 1.2660106965065003\n",
      "Epoka [5/10], Strata treningowa: 1.1948280248850585\n",
      "Epoka [6/10], Strata treningowa: 1.136150265571144\n",
      "Epoka [7/10], Strata treningowa: 1.0861038734777106\n",
      "Strata walidacyjna po epoce: 1.1136575412869454\n",
      "Epoka [8/10], Strata treningowa: 1.037539607566264\n",
      "Epoka [9/10], Strata treningowa: 0.9965576647480329\n",
      "Epoka [10/10], Strata treningowa: 0.9584461677061187\n",
      "Strata walidacyjna po epoce: 1.0057642030924558\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5622088888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 14:39:59,805] Trial 0 finished with value: 0.6466 and parameters: {'lr': 0.00010143819035635126, 'n_layers': 3, 'conv_out': 112, 'kernel_size': 3}. Best is trial 0 with value: 0.6466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 243974\n",
      "Epoka [1/10], Strata treningowa: 1.8741868538485633\n",
      "Strata walidacyjna po epoce: 1.737463948059082\n",
      "Epoka [2/10], Strata treningowa: 1.5836104803535673\n",
      "Epoka [3/10], Strata treningowa: 1.453301278327571\n",
      "Epoka [4/10], Strata treningowa: 1.3603646741721365\n",
      "Strata walidacyjna po epoce: 1.3358355244636535\n",
      "Epoka [5/10], Strata treningowa: 1.2827120516134634\n",
      "Epoka [6/10], Strata treningowa: 1.2130436745233006\n",
      "Epoka [7/10], Strata treningowa: 1.14946362847156\n",
      "Strata walidacyjna po epoce: 1.1393958956420422\n",
      "Epoka [8/10], Strata treningowa: 1.090080336607496\n",
      "Epoka [9/10], Strata treningowa: 1.0352545496318075\n",
      "Epoka [10/10], Strata treningowa: 0.9858781962315242\n",
      "Strata walidacyjna po epoce: 1.015169109135866\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5225822222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 14:49:26,147] Trial 1 finished with value: 0.6397 and parameters: {'lr': 0.00011268202500741872, 'n_layers': 5, 'conv_out': 80, 'kernel_size': 3}. Best is trial 0 with value: 0.6466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 74710\n",
      "Epoka [1/10], Strata treningowa: 1.6318000225822131\n",
      "Strata walidacyjna po epoce: 1.3861239825367928\n",
      "Epoka [2/10], Strata treningowa: 1.2671061653183566\n",
      "Epoka [3/10], Strata treningowa: 1.0993060731046729\n",
      "Epoka [4/10], Strata treningowa: 0.9830650430240565\n",
      "Strata walidacyjna po epoce: 0.9735217805281281\n",
      "Epoka [5/10], Strata treningowa: 0.8914548373346527\n",
      "Epoka [6/10], Strata treningowa: 0.8217993717779716\n",
      "Epoka [7/10], Strata treningowa: 0.7606800521505376\n",
      "Strata walidacyjna po epoce: 0.8697535689627752\n",
      "Epoka [8/10], Strata treningowa: 0.7121282049265173\n",
      "Epoka [9/10], Strata treningowa: 0.669033395160507\n",
      "Epoka [10/10], Strata treningowa: 0.6284908876480949\n",
      "Strata walidacyjna po epoce: 0.7757006527874619\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6596177777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 14:56:00,016] Trial 2 finished with value: 0.7228 and parameters: {'lr': 0.0006563429051190292, 'n_layers': 4, 'conv_out': 48, 'kernel_size': 3}. Best is trial 2 with value: 0.7228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 479302\n",
      "Epoka [1/10], Strata treningowa: 1.5099589594284692\n",
      "Strata walidacyjna po epoce: 1.243891344898939\n",
      "Epoka [2/10], Strata treningowa: 1.1595247326834335\n",
      "Epoka [3/10], Strata treningowa: 1.010072269544171\n",
      "Epoka [4/10], Strata treningowa: 0.9075255134181223\n",
      "Strata walidacyjna po epoce: 0.9818330199766904\n",
      "Epoka [5/10], Strata treningowa: 0.8261875429627796\n",
      "Epoka [6/10], Strata treningowa: 0.766333394723101\n",
      "Epoka [7/10], Strata treningowa: 0.7079422797922122\n",
      "Strata walidacyjna po epoce: 0.9049576090652496\n",
      "Epoka [8/10], Strata treningowa: 0.6581637147196207\n",
      "Epoka [9/10], Strata treningowa: 0.6102156542618112\n",
      "Epoka [10/10], Strata treningowa: 0.577094526383172\n",
      "Strata walidacyjna po epoce: 0.9610902199016768\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6915466666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:07:36,358] Trial 3 finished with value: 0.6956 and parameters: {'lr': 0.0010237011214945877, 'n_layers': 3, 'conv_out': 96, 'kernel_size': 5}. Best is trial 2 with value: 0.7228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 123590\n",
      "Epoka [1/10], Strata treningowa: 1.8086981124666002\n",
      "Strata walidacyjna po epoce: 1.6383831911563873\n",
      "Epoka [2/10], Strata treningowa: 1.5684308673090406\n",
      "Epoka [3/10], Strata treningowa: 1.4424640851140023\n",
      "Epoka [4/10], Strata treningowa: 1.3513241511291927\n",
      "Strata walidacyjna po epoce: 1.3206543737888337\n",
      "Epoka [5/10], Strata treningowa: 1.2786445554852486\n",
      "Epoka [6/10], Strata treningowa: 1.2158422282000383\n",
      "Epoka [7/10], Strata treningowa: 1.1632175943546825\n",
      "Strata walidacyjna po epoce: 1.1990242166399956\n",
      "Epoka [8/10], Strata treningowa: 1.1157138848652441\n",
      "Epoka [9/10], Strata treningowa: 1.0717990810349585\n",
      "Epoka [10/10], Strata treningowa: 1.0312404241727458\n",
      "Strata walidacyjna po epoce: 1.0512972566246985\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5275177777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:14:55,683] Trial 4 finished with value: 0.6254 and parameters: {'lr': 0.00012003847018675302, 'n_layers': 4, 'conv_out': 64, 'kernel_size': 3}. Best is trial 2 with value: 0.7228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 16102\n",
      "Epoka [1/10], Strata treningowa: 1.8559347128550212\n",
      "Strata walidacyjna po epoce: 1.733749787759781\n",
      "Epoka [2/10], Strata treningowa: 1.7294070784807205\n",
      "Epoka [3/10], Strata treningowa: 1.6938529605468113\n",
      "Epoka [4/10], Strata treningowa: 1.6662689923710294\n",
      "Strata walidacyjna po epoce: 1.7085443233728408\n",
      "Epoka [5/10], Strata treningowa: 1.6492031017541886\n",
      "Epoka [6/10], Strata treningowa: 1.6459998306393624\n",
      "Epoka [7/10], Strata treningowa: 1.6377522967179616\n",
      "Strata walidacyjna po epoce: 1.6946823536157607\n",
      "Epoka [8/10], Strata treningowa: 1.6391847740226322\n",
      "Epoka [9/10], Strata treningowa: 1.6301108431551192\n",
      "Epoka [10/10], Strata treningowa: 1.6261266589164733\n",
      "Strata walidacyjna po epoce: 1.6349909375667573\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.3802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:19:22,480] Trial 5 finished with value: 0.3881 and parameters: {'lr': 0.009875864229059743, 'n_layers': 3, 'conv_out': 16, 'kernel_size': 3}. Best is trial 2 with value: 0.7228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 11894\n",
      "Epoka [1/10], Strata treningowa: 2.045478460963567\n",
      "Strata walidacyjna po epoce: 1.9694999514102935\n",
      "Epoka [2/10], Strata treningowa: 1.8936079549206628\n",
      "Epoka [3/10], Strata treningowa: 1.817607074769338\n",
      "Epoka [4/10], Strata treningowa: 1.7768638203965292\n",
      "Strata walidacyjna po epoce: 1.7811098039627076\n",
      "Epoka [5/10], Strata treningowa: 1.7499998675372865\n",
      "Epoka [6/10], Strata treningowa: 1.727816850540373\n",
      "Epoka [7/10], Strata treningowa: 1.7088928550216886\n",
      "Strata walidacyjna po epoce: 1.7134653786182403\n",
      "Epoka [8/10], Strata treningowa: 1.692670890900824\n",
      "Epoka [9/10], Strata treningowa: 1.6788300786336263\n",
      "Epoka [10/10], Strata treningowa: 1.665327638665835\n",
      "Strata walidacyjna po epoce: 1.6742548828125\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.3555422222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:24:10,625] Trial 6 finished with value: 0.4076 and parameters: {'lr': 0.00027670456399496484, 'n_layers': 4, 'conv_out': 16, 'kernel_size': 1}. Best is trial 2 with value: 0.7228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 709798\n",
      "Epoka [1/10], Strata treningowa: 1.9669580615202586\n",
      "Strata walidacyjna po epoce: 1.8609989902019501\n",
      "Epoka [2/10], Strata treningowa: 1.7959428497897254\n",
      "Epoka [3/10], Strata treningowa: 1.720390819480684\n",
      "Epoka [4/10], Strata treningowa: 1.6705746939526664\n",
      "Strata walidacyjna po epoce: 1.655841153907776\n",
      "Epoka [5/10], Strata treningowa: 1.625913265238868\n",
      "Epoka [6/10], Strata treningowa: 1.5869340513361825\n",
      "Epoka [7/10], Strata treningowa: 1.5507136482477188\n",
      "Strata walidacyjna po epoce: 1.5552743984699249\n",
      "Epoka [8/10], Strata treningowa: 1.520257308157285\n",
      "Epoka [9/10], Strata treningowa: 1.4929814780831336\n",
      "Epoka [10/10], Strata treningowa: 1.4665893833769692\n",
      "Strata walidacyjna po epoce: 1.4767684287548066\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.39869333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:36:22,062] Trial 7 finished with value: 0.472 and parameters: {'lr': 1.027682713387195e-05, 'n_layers': 4, 'conv_out': 96, 'kernel_size': 5}. Best is trial 2 with value: 0.7228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 37894\n",
      "Epoka [1/10], Strata treningowa: 2.1333379267268713\n",
      "Strata walidacyjna po epoce: 2.056286244392395\n",
      "Epoka [2/10], Strata treningowa: 2.006883700328403\n",
      "Epoka [3/10], Strata treningowa: 1.9414705910152859\n",
      "Epoka [4/10], Strata treningowa: 1.888640539206399\n",
      "Strata walidacyjna po epoce: 1.8781769868850708\n",
      "Epoka [5/10], Strata treningowa: 1.84243581633038\n",
      "Epoka [6/10], Strata treningowa: 1.8133981151368883\n",
      "Epoka [7/10], Strata treningowa: 1.7937051557752821\n",
      "Strata walidacyjna po epoce: 1.8107218222141266\n",
      "Epoka [8/10], Strata treningowa: 1.7774763719876607\n",
      "Epoka [9/10], Strata treningowa: 1.760723648542828\n",
      "Epoka [10/10], Strata treningowa: 1.746578562148412\n",
      "Strata walidacyjna po epoce: 1.758865368461609\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.2860311111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:42:14,430] Trial 8 finished with value: 0.3474 and parameters: {'lr': 2.3430026289740978e-05, 'n_layers': 5, 'conv_out': 16, 'kernel_size': 5}. Best is trial 2 with value: 0.7228.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 95494\n",
      "Epoka [1/10], Strata treningowa: 1.6802333391997548\n",
      "Strata walidacyjna po epoce: 1.434176861691475\n",
      "Epoka [2/10], Strata treningowa: 1.334117326174842\n",
      "Epoka [3/10], Strata treningowa: 1.1461843353748322\n",
      "Epoka [4/10], Strata treningowa: 1.0226108544086416\n",
      "Strata walidacyjna po epoce: 1.0132465562328696\n",
      "Epoka [5/10], Strata treningowa: 0.9264096184483833\n",
      "Epoka [6/10], Strata treningowa: 0.845708187786407\n",
      "Epoka [7/10], Strata treningowa: 0.7830392151269234\n",
      "Strata walidacyjna po epoce: 0.8401846417039632\n",
      "Epoka [8/10], Strata treningowa: 0.7239458499847601\n",
      "Epoka [9/10], Strata treningowa: 0.6729610386266683\n",
      "Epoka [10/10], Strata treningowa: 0.6324558426518614\n",
      "Strata walidacyjna po epoce: 0.79211689055413\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6475311111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:49:32,099] Trial 9 finished with value: 0.7247 and parameters: {'lr': 0.0005539361207466788, 'n_layers': 5, 'conv_out': 48, 'kernel_size': 3}. Best is trial 9 with value: 0.7247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 48, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 13558\n",
      "Epoka [1/10], Strata treningowa: 1.7056439922147326\n",
      "Strata walidacyjna po epoce: 1.6536541638612747\n",
      "Epoka [2/10], Strata treningowa: 1.5618726715485254\n",
      "Epoka [3/10], Strata treningowa: 1.5151714123129845\n",
      "Epoka [4/10], Strata treningowa: 1.4886957363771067\n",
      "Strata walidacyjna po epoce: 1.612344684290886\n",
      "Epoka [5/10], Strata treningowa: 1.4712251934753524\n",
      "Epoka [6/10], Strata treningowa: 1.4548087969289885\n",
      "Epoka [7/10], Strata treningowa: 1.442665681608518\n",
      "Strata walidacyjna po epoce: 1.5130408646702767\n",
      "Epoka [8/10], Strata treningowa: 1.4357222299112213\n",
      "Epoka [9/10], Strata treningowa: 1.426017259940836\n",
      "Epoka [10/10], Strata treningowa: 1.4175819360911845\n",
      "Strata walidacyjna po epoce: 1.5026926325321197\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.46138222222222225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 15:54:25,942] Trial 10 finished with value: 0.4709 and parameters: {'lr': 0.0033127230301659046, 'n_layers': 2, 'conv_out': 48, 'kernel_size': 1}. Best is trial 9 with value: 0.7247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 48, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 20614\n",
      "Epoka [1/10], Strata treningowa: 1.9860317950619593\n",
      "Strata walidacyjna po epoce: 1.9567378371238708\n",
      "Epoka [2/10], Strata treningowa: 1.858194554037518\n",
      "Epoka [3/10], Strata treningowa: 1.7748237617015838\n",
      "Epoka [4/10], Strata treningowa: 1.715762656349606\n",
      "Strata walidacyjna po epoce: 1.742421763586998\n",
      "Epoka [5/10], Strata treningowa: 1.6824954154332479\n",
      "Epoka [6/10], Strata treningowa: 1.6572484638108147\n",
      "Epoka [7/10], Strata treningowa: 1.6349934254169465\n",
      "Strata walidacyjna po epoce: 1.6690924050331115\n",
      "Epoka [8/10], Strata treningowa: 1.6140672245780627\n",
      "Epoka [9/10], Strata treningowa: 1.5973641686571969\n",
      "Epoka [10/10], Strata treningowa: 1.5768245357831319\n",
      "Strata walidacyjna po epoce: 1.5982384656190871\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.3745777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:01:09,289] Trial 11 finished with value: 0.4372 and parameters: {'lr': 0.0009533564133593521, 'n_layers': 5, 'conv_out': 48, 'kernel_size': 1}. Best is trial 9 with value: 0.7247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 95494\n",
      "Epoka [1/10], Strata treningowa: 1.6776004874957933\n",
      "Strata walidacyjna po epoce: 1.448519480752945\n",
      "Epoka [2/10], Strata treningowa: 1.3065392182423008\n",
      "Epoka [3/10], Strata treningowa: 1.1349103365474278\n",
      "Epoka [4/10], Strata treningowa: 1.0105628633866708\n",
      "Strata walidacyjna po epoce: 1.0805600738301873\n",
      "Epoka [5/10], Strata treningowa: 0.9202563055694103\n",
      "Epoka [6/10], Strata treningowa: 0.8493617946229876\n",
      "Epoka [7/10], Strata treningowa: 0.7877971989766591\n",
      "Strata walidacyjna po epoce: 0.8528186394814402\n",
      "Epoka [8/10], Strata treningowa: 0.7387139402177185\n",
      "Epoka [9/10], Strata treningowa: 0.6971582795453568\n",
      "Epoka [10/10], Strata treningowa: 0.6640695506585969\n",
      "Strata walidacyjna po epoce: 0.7892471284538507\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6486066666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:08:24,931] Trial 12 finished with value: 0.7214 and parameters: {'lr': 0.0008464499382640642, 'n_layers': 5, 'conv_out': 48, 'kernel_size': 3}. Best is trial 9 with value: 0.7247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 123590\n",
      "Epoka [1/10], Strata treningowa: 1.619211789751053\n",
      "Strata walidacyjna po epoce: 1.455256283724308\n",
      "Epoka [2/10], Strata treningowa: 1.271817446195417\n",
      "Epoka [3/10], Strata treningowa: 1.1061695217774974\n",
      "Epoka [4/10], Strata treningowa: 0.9864240883377691\n",
      "Strata walidacyjna po epoce: 0.9752540271162987\n",
      "Epoka [5/10], Strata treningowa: 0.890536716277649\n",
      "Epoka [6/10], Strata treningowa: 0.8152897959426045\n",
      "Epoka [7/10], Strata treningowa: 0.7479557908264506\n",
      "Strata walidacyjna po epoce: 0.79975136179775\n",
      "Epoka [8/10], Strata treningowa: 0.6907806066057748\n",
      "Epoka [9/10], Strata treningowa: 0.6419850698219819\n",
      "Epoka [10/10], Strata treningowa: 0.5958720162237167\n",
      "Strata walidacyjna po epoce: 0.7410592326601967\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6631866666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:15:55,523] Trial 13 finished with value: 0.7373 and parameters: {'lr': 0.00046434187070760514, 'n_layers': 4, 'conv_out': 64, 'kernel_size': 3}. Best is trial 13 with value: 0.7373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 77574\n",
      "Epoka [1/10], Strata treningowa: 1.943661880376604\n",
      "Strata walidacyjna po epoce: 1.9002242376804352\n",
      "Epoka [2/10], Strata treningowa: 1.7970043550597297\n",
      "Epoka [3/10], Strata treningowa: 1.73329579472012\n",
      "Epoka [4/10], Strata treningowa: 1.7003881055540508\n",
      "Strata walidacyjna po epoce: 1.7142027740716934\n",
      "Epoka [5/10], Strata treningowa: 1.6700648134920333\n",
      "Epoka [6/10], Strata treningowa: 1.6453736192809212\n",
      "Epoka [7/10], Strata treningowa: 1.6241408793793783\n",
      "Strata walidacyjna po epoce: 1.6617944264411926\n",
      "Epoka [8/10], Strata treningowa: 1.6031534031099743\n",
      "Epoka [9/10], Strata treningowa: 1.5886132146861818\n",
      "Epoka [10/10], Strata treningowa: 1.5711146603372361\n",
      "Strata walidacyjna po epoce: 1.6063536930084228\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.38569777777777775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:26:20,803] Trial 14 finished with value: 0.429 and parameters: {'lr': 0.0028388030868808315, 'n_layers': 5, 'conv_out': 128, 'kernel_size': 1}. Best is trial 13 with value: 0.7373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 323270\n",
      "Epoka [1/10], Strata treningowa: 1.5838437097668647\n",
      "Strata walidacyjna po epoce: 1.31433412348032\n",
      "Epoka [2/10], Strata treningowa: 1.1876121116373275\n",
      "Epoka [3/10], Strata treningowa: 0.9892771530760659\n",
      "Epoka [4/10], Strata treningowa: 0.8520239819185601\n",
      "Strata walidacyjna po epoce: 0.8411208393529057\n",
      "Epoka [5/10], Strata treningowa: 0.7442990399745577\n",
      "Epoka [6/10], Strata treningowa: 0.6565277408439485\n",
      "Epoka [7/10], Strata treningowa: 0.5807111259910045\n",
      "Strata walidacyjna po epoce: 0.7049962358307094\n",
      "Epoka [8/10], Strata treningowa: 0.5157972099381384\n",
      "Epoka [9/10], Strata treningowa: 0.4547307418253208\n",
      "Epoka [10/10], Strata treningowa: 0.3974906931005179\n",
      "Strata walidacyjna po epoce: 0.7175352697828319\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7158444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:34:57,912] Trial 15 finished with value: 0.758 and parameters: {'lr': 0.0003275478547485174, 'n_layers': 4, 'conv_out': 64, 'kernel_size': 5}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 80, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Conv2d(80, 80, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 177174\n",
      "Epoka [1/10], Strata treningowa: 1.61388285015689\n",
      "Strata walidacyjna po epoce: 1.4611972734928131\n",
      "Epoka [2/10], Strata treningowa: 1.3449015722168816\n",
      "Epoka [3/10], Strata treningowa: 1.2385386545677979\n",
      "Epoka [4/10], Strata treningowa: 1.159650565420919\n",
      "Strata walidacyjna po epoce: 1.1981572269320488\n",
      "Epoka [5/10], Strata treningowa: 1.0955925101286834\n",
      "Epoka [6/10], Strata treningowa: 1.0408601144540641\n",
      "Epoka [7/10], Strata treningowa: 0.993948008117742\n",
      "Strata walidacyjna po epoce: 1.0758712421894074\n",
      "Epoka [8/10], Strata treningowa: 0.9550093769740727\n",
      "Epoka [9/10], Strata treningowa: 0.9181909067446987\n",
      "Epoka [10/10], Strata treningowa: 0.8847814430679712\n",
      "Strata walidacyjna po epoce: 1.0007328067064285\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5982333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:42:58,173] Trial 16 finished with value: 0.6481 and parameters: {'lr': 0.00024486155761967274, 'n_layers': 2, 'conv_out': 80, 'kernel_size': 5}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 323270\n",
      "Epoka [1/10], Strata treningowa: 1.8224061352994707\n",
      "Strata walidacyjna po epoce: 1.7211089388132095\n",
      "Epoka [2/10], Strata treningowa: 1.5689126659711201\n",
      "Epoka [3/10], Strata treningowa: 1.4590091175542936\n",
      "Epoka [4/10], Strata treningowa: 1.3747940257257885\n",
      "Strata walidacyjna po epoce: 1.4087283687829972\n",
      "Epoka [5/10], Strata treningowa: 1.2935330103211933\n",
      "Epoka [6/10], Strata treningowa: 1.218490552789635\n",
      "Epoka [7/10], Strata treningowa: 1.1506964662227366\n",
      "Strata walidacyjna po epoce: 1.1340856690883636\n",
      "Epoka [8/10], Strata treningowa: 1.091503902087609\n",
      "Epoka [9/10], Strata treningowa: 1.036696173443728\n",
      "Epoka [10/10], Strata treningowa: 0.9887863567408588\n",
      "Strata walidacyjna po epoce: 1.010657949024439\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5269866666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:51:17,168] Trial 17 finished with value: 0.6422 and parameters: {'lr': 5.744697064368321e-05, 'n_layers': 4, 'conv_out': 64, 'kernel_size': 5}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 64710\n",
      "Epoka [1/10], Strata treningowa: 1.726404450477494\n",
      "Strata walidacyjna po epoce: 1.6224047280311584\n",
      "Epoka [2/10], Strata treningowa: 1.537009518500169\n",
      "Epoka [3/10], Strata treningowa: 1.47298431501521\n",
      "Epoka [4/10], Strata treningowa: 1.4181221810089217\n",
      "Strata walidacyjna po epoce: 1.416572156882286\n",
      "Epoka [5/10], Strata treningowa: 1.3651809747722414\n",
      "Epoka [6/10], Strata treningowa: 1.3171577188379235\n",
      "Epoka [7/10], Strata treningowa: 1.2724214082668226\n",
      "Strata walidacyjna po epoce: 1.252861666804552\n",
      "Epoka [8/10], Strata treningowa: 1.2364502461330757\n",
      "Epoka [9/10], Strata treningowa: 1.2037135446056724\n",
      "Epoka [10/10], Strata treningowa: 1.1692340807538892\n",
      "Strata walidacyjna po epoce: 1.2737436866819858\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5039977777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 16:56:28,066] Trial 18 finished with value: 0.5614 and parameters: {'lr': 0.0026543549951504554, 'n_layers': 3, 'conv_out': 32, 'kernel_size': 5}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 262822\n",
      "Epoka [1/10], Strata treningowa: 1.6033007426473829\n",
      "Strata walidacyjna po epoce: 1.3606264086723328\n",
      "Epoka [2/10], Strata treningowa: 1.24467583265437\n",
      "Epoka [3/10], Strata treningowa: 1.067891506349047\n",
      "Epoka [4/10], Strata treningowa: 0.9478333749921786\n",
      "Strata walidacyjna po epoce: 0.9464500913858414\n",
      "Epoka [5/10], Strata treningowa: 0.8485373514658875\n",
      "Epoka [6/10], Strata treningowa: 0.7739834627554545\n",
      "Epoka [7/10], Strata treningowa: 0.7059402529635053\n",
      "Strata walidacyjna po epoce: 0.8195505285620689\n",
      "Epoka [8/10], Strata treningowa: 0.648383188162475\n",
      "Epoka [9/10], Strata treningowa: 0.5907662145487472\n",
      "Epoka [10/10], Strata treningowa: 0.5400736353400991\n",
      "Strata walidacyjna po epoce: 0.7332844154300168\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6788066666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 17:05:53,955] Trial 19 finished with value: 0.7433 and parameters: {'lr': 0.0003294559505602095, 'n_layers': 4, 'conv_out': 96, 'kernel_size': 3}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 479302\n",
      "Epoka [1/10], Strata treningowa: 1.8132285944779714\n",
      "Strata walidacyjna po epoce: 1.6571880141735076\n",
      "Epoka [2/10], Strata treningowa: 1.5525190848085615\n",
      "Epoka [3/10], Strata treningowa: 1.4404561604910426\n",
      "Epoka [4/10], Strata treningowa: 1.3675172858688567\n",
      "Strata walidacyjna po epoce: 1.3713354489564895\n",
      "Epoka [5/10], Strata treningowa: 1.3143318018496037\n",
      "Epoka [6/10], Strata treningowa: 1.2670518246697056\n",
      "Epoka [7/10], Strata treningowa: 1.223728012365765\n",
      "Strata walidacyjna po epoce: 1.2483127687573432\n",
      "Epoka [8/10], Strata treningowa: 1.1808496194905704\n",
      "Epoka [9/10], Strata treningowa: 1.1402602965301938\n",
      "Epoka [10/10], Strata treningowa: 1.101102140108082\n",
      "Strata walidacyjna po epoce: 1.129846738153696\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5207511111111112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 18:30:32,121] Trial 20 finished with value: 0.598 and parameters: {'lr': 3.595260844822617e-05, 'n_layers': 3, 'conv_out': 96, 'kernel_size': 5}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 186294\n",
      "Epoka [1/10], Strata treningowa: 1.6158595750835207\n",
      "Strata walidacyjna po epoce: 1.3980476068019867\n",
      "Epoka [2/10], Strata treningowa: 1.28500499495599\n",
      "Epoka [3/10], Strata treningowa: 1.1261977045837377\n",
      "Epoka [4/10], Strata treningowa: 1.0096919651541445\n",
      "Strata walidacyjna po epoce: 0.9853082850635052\n",
      "Epoka [5/10], Strata treningowa: 0.914152674288551\n",
      "Epoka [6/10], Strata treningowa: 0.838125578699592\n",
      "Epoka [7/10], Strata treningowa: 0.7741680820643695\n",
      "Strata walidacyjna po epoce: 0.8822716104537248\n",
      "Epoka [8/10], Strata treningowa: 0.7161953760366887\n",
      "Epoka [9/10], Strata treningowa: 0.6645370953450808\n",
      "Epoka [10/10], Strata treningowa: 0.6165293711088183\n",
      "Strata walidacyjna po epoce: 0.824401992930565\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6574488888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 18:39:12,915] Trial 21 finished with value: 0.7174 and parameters: {'lr': 0.00030983301651348635, 'n_layers': 4, 'conv_out': 80, 'kernel_size': 3}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 123590\n",
      "Epoka [1/10], Strata treningowa: 1.7540822641876008\n",
      "Strata walidacyjna po epoce: 1.5845282210111618\n",
      "Epoka [2/10], Strata treningowa: 1.4892088274584876\n",
      "Epoka [3/10], Strata treningowa: 1.3523563024202983\n",
      "Epoka [4/10], Strata treningowa: 1.2540115782121817\n",
      "Strata walidacyjna po epoce: 1.2450853363633156\n",
      "Epoka [5/10], Strata treningowa: 1.1723790568828583\n",
      "Epoka [6/10], Strata treningowa: 1.106622950479057\n",
      "Epoka [7/10], Strata treningowa: 1.0508295224939783\n",
      "Strata walidacyjna po epoce: 1.0742269305542111\n",
      "Epoka [8/10], Strata treningowa: 1.000261934032374\n",
      "Epoka [9/10], Strata treningowa: 0.9551468900733524\n",
      "Epoka [10/10], Strata treningowa: 0.9129039793464044\n",
      "Strata walidacyjna po epoce: 1.0038955788344144\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5637822222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 18:46:51,234] Trial 22 finished with value: 0.6492 and parameters: {'lr': 0.00016406698877034778, 'n_layers': 4, 'conv_out': 64, 'kernel_size': 3}. Best is trial 15 with value: 0.758.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 353174\n",
      "Epoka [1/10], Strata treningowa: 1.5579418525550102\n",
      "Strata walidacyjna po epoce: 1.3492040729641914\n",
      "Epoka [2/10], Strata treningowa: 1.180829980435305\n",
      "Epoka [3/10], Strata treningowa: 0.9937647968293064\n",
      "Epoka [4/10], Strata treningowa: 0.864323211216016\n",
      "Strata walidacyjna po epoce: 0.9093719008021056\n",
      "Epoka [5/10], Strata treningowa: 0.7660772526662797\n",
      "Epoka [6/10], Strata treningowa: 0.685502732180742\n",
      "Epoka [7/10], Strata treningowa: 0.6135261049128138\n",
      "Strata walidacyjna po epoce: 0.6986903945699334\n",
      "Epoka [8/10], Strata treningowa: 0.5546069539141635\n",
      "Epoka [9/10], Strata treningowa: 0.5016151650679738\n",
      "Epoka [10/10], Strata treningowa: 0.4498211600284849\n",
      "Strata walidacyjna po epoce: 0.7027924500645604\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.70786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 18:59:11,887] Trial 23 finished with value: 0.7618 and parameters: {'lr': 0.00045352634303509143, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 61062\n",
      "Epoka [1/10], Strata treningowa: 1.8356378408193588\n",
      "Strata walidacyjna po epoce: 1.703606545162201\n",
      "Epoka [2/10], Strata treningowa: 1.6515846430593066\n",
      "Epoka [3/10], Strata treningowa: 1.5808323594596652\n",
      "Epoka [4/10], Strata treningowa: 1.5410522243181863\n",
      "Strata walidacyjna po epoce: 1.5843410361528396\n",
      "Epoka [5/10], Strata treningowa: 1.512691990492079\n",
      "Epoka [6/10], Strata treningowa: 1.489248692995972\n",
      "Epoka [7/10], Strata treningowa: 1.4679557442678346\n",
      "Strata walidacyjna po epoce: 1.5060900191783906\n",
      "Epoka [8/10], Strata treningowa: 1.4498660943918757\n",
      "Epoka [9/10], Strata treningowa: 1.4342632232930925\n",
      "Epoka [10/10], Strata treningowa: 1.419755621290869\n",
      "Strata walidacyjna po epoce: 1.4689100913286208\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.44081777777777775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 19:09:25,188] Trial 24 finished with value: 0.4782 and parameters: {'lr': 0.0017292022550697771, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 1}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 240166\n",
      "Epoka [1/10], Strata treningowa: 1.6053217434830136\n",
      "Strata walidacyjna po epoce: 1.423397826051712\n",
      "Epoka [2/10], Strata treningowa: 1.3047877529627747\n",
      "Epoka [3/10], Strata treningowa: 1.1677334321624704\n",
      "Epoka [4/10], Strata treningowa: 1.0609747550568647\n",
      "Strata walidacyjna po epoce: 1.042313637304306\n",
      "Epoka [5/10], Strata treningowa: 0.9791031241748068\n",
      "Epoka [6/10], Strata treningowa: 0.9097289976838562\n",
      "Epoka [7/10], Strata treningowa: 0.8542530777424574\n",
      "Strata walidacyjna po epoce: 0.8920591451495886\n",
      "Epoka [8/10], Strata treningowa: 0.7994755551721694\n",
      "Epoka [9/10], Strata treningowa: 0.7568435038797972\n",
      "Epoka [10/10], Strata treningowa: 0.7149992914653487\n",
      "Strata walidacyjna po epoce: 0.8570509404405952\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6364133333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 19:20:13,376] Trial 25 finished with value: 0.7022 and parameters: {'lr': 0.00021353312920846597, 'n_layers': 3, 'conv_out': 112, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(112, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 960662\n",
      "Epoka [1/10], Strata treningowa: 1.5808649455706278\n",
      "Strata walidacyjna po epoce: 1.2867586978197099\n",
      "Epoka [2/10], Strata treningowa: 1.1604172626278466\n",
      "Epoka [3/10], Strata treningowa: 0.9468351910925987\n",
      "Epoka [4/10], Strata treningowa: 0.8006741922471827\n",
      "Strata walidacyjna po epoce: 0.8375020239565522\n",
      "Epoka [5/10], Strata treningowa: 0.6873042040530593\n",
      "Epoka [6/10], Strata treningowa: 0.5955681058992425\n",
      "Epoka [7/10], Strata treningowa: 0.5115750509947564\n",
      "Strata walidacyjna po epoce: 0.7549368641014211\n",
      "Epoka [8/10], Strata treningowa: 0.4345919398734747\n",
      "Epoka [9/10], Strata treningowa: 0.3683234456454924\n",
      "Epoka [10/10], Strata treningowa: 0.3133725467324118\n",
      "Strata walidacyjna po epoce: 0.845443920789627\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7369066666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 19:37:22,226] Trial 26 finished with value: 0.7492 and parameters: {'lr': 0.0004090266982139441, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 5}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(112, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 960662\n",
      "Epoka [1/10], Strata treningowa: 2.303334655274285\n",
      "Strata walidacyjna po epoce: 2.304470374298096\n",
      "Epoka [2/10], Strata treningowa: 2.303330620659722\n",
      "Epoka [3/10], Strata treningowa: 2.3032150570551555\n",
      "Epoka [4/10], Strata treningowa: 2.303240148035685\n",
      "Strata walidacyjna po epoce: 2.3029070657730104\n",
      "Epoka [5/10], Strata treningowa: 2.3031719871520995\n",
      "Epoka [6/10], Strata treningowa: 2.3032853590011597\n",
      "Epoka [7/10], Strata treningowa: 2.303323718028598\n",
      "Strata walidacyjna po epoce: 2.3035875368118286\n",
      "Epoka [8/10], Strata treningowa: 2.3031893831888834\n",
      "Epoka [9/10], Strata treningowa: 2.303312819290161\n",
      "Epoka [10/10], Strata treningowa: 2.30328850578732\n",
      "Strata walidacyjna po epoce: 2.302549613189697\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.09869555555555555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 19:55:31,831] Trial 27 finished with value: 0.1 and parameters: {'lr': 0.0016027936020383256, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 5}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 840198\n",
      "Epoka [1/10], Strata treningowa: 1.4658503614577982\n",
      "Strata walidacyjna po epoce: 1.2151772014260291\n",
      "Epoka [2/10], Strata treningowa: 1.088758809112592\n",
      "Epoka [3/10], Strata treningowa: 0.9090042044821712\n",
      "Epoka [4/10], Strata treningowa: 0.7825442663025111\n",
      "Strata walidacyjna po epoce: 0.8974598126709461\n",
      "Epoka [5/10], Strata treningowa: 0.6844929889975426\n",
      "Epoka [6/10], Strata treningowa: 0.5990901678923052\n",
      "Epoka [7/10], Strata treningowa: 0.5255007389044699\n",
      "Strata walidacyjna po epoce: 0.8477149700840935\n",
      "Epoka [8/10], Strata treningowa: 0.46210899259370636\n",
      "Epoka [9/10], Strata treningowa: 0.4035768599753606\n",
      "Epoka [10/10], Strata treningowa: 0.3539636962100441\n",
      "Strata walidacyjna po epoce: 0.962801467590197\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7411733333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 20:12:48,966] Trial 28 finished with value: 0.7334 and parameters: {'lr': 0.0004723076757775508, 'n_layers': 3, 'conv_out': 128, 'kernel_size': 5}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Conv2d(112, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 333238\n",
      "Epoka [1/10], Strata treningowa: 1.7184204156769647\n",
      "Strata walidacyjna po epoce: 1.548541509771347\n",
      "Epoka [2/10], Strata treningowa: 1.4316747109969457\n",
      "Epoka [3/10], Strata treningowa: 1.335681557548046\n",
      "Epoka [4/10], Strata treningowa: 1.2764079942670132\n",
      "Strata walidacyjna po epoce: 1.3016265209436417\n",
      "Epoka [5/10], Strata treningowa: 1.2262940188811886\n",
      "Epoka [6/10], Strata treningowa: 1.1829563715034062\n",
      "Epoka [7/10], Strata treningowa: 1.1413558461848232\n",
      "Strata walidacyjna po epoce: 1.1942222630143167\n",
      "Epoka [8/10], Strata treningowa: 1.1050454593582286\n",
      "Epoka [9/10], Strata treningowa: 1.0707733673132127\n",
      "Epoka [10/10], Strata treningowa: 1.037520750688182\n",
      "Strata walidacyjna po epoce: 1.139755612027645\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5539955555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 20:25:10,269] Trial 29 finished with value: 0.597 and parameters: {'lr': 8.180980335831255e-05, 'n_layers': 2, 'conv_out': 112, 'kernel_size': 5}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(112, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 1274374\n",
      "Epoka [1/10], Strata treningowa: 2.305612261221144\n",
      "Strata walidacyjna po epoce: 2.3044670150756836\n",
      "Epoka [2/10], Strata treningowa: 2.3047090948528712\n",
      "Epoka [3/10], Strata treningowa: 2.304727593506707\n",
      "Epoka [4/10], Strata treningowa: 2.304796145078871\n",
      "Strata walidacyjna po epoce: 2.3048620727539064\n",
      "Epoka [5/10], Strata treningowa: 2.3048827070236206\n",
      "Epoka [6/10], Strata treningowa: 2.3049995876312255\n",
      "Epoka [7/10], Strata treningowa: 2.3052037995868258\n",
      "Strata walidacyjna po epoce: 2.3053421268463135\n",
      "Epoka [8/10], Strata treningowa: 2.305027985551622\n",
      "Epoka [9/10], Strata treningowa: 2.304915890312195\n",
      "Epoka [10/10], Strata treningowa: 2.3052720529132418\n",
      "Strata walidacyjna po epoce: 2.3032272144317627\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.09932444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 20:45:00,388] Trial 30 finished with value: 0.1 and parameters: {'lr': 0.0062234144513133175, 'n_layers': 5, 'conv_out': 112, 'kernel_size': 5}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 262822\n",
      "Epoka [1/10], Strata treningowa: 1.579543449543582\n",
      "Strata walidacyjna po epoce: 1.3417554251909256\n",
      "Epoka [2/10], Strata treningowa: 1.2380052543229527\n",
      "Epoka [3/10], Strata treningowa: 1.0687757886115048\n",
      "Epoka [4/10], Strata treningowa: 0.94030793141197\n",
      "Strata walidacyjna po epoce: 0.9242001174509525\n",
      "Epoka [5/10], Strata treningowa: 0.838567335619943\n",
      "Epoka [6/10], Strata treningowa: 0.7530031716266026\n",
      "Epoka [7/10], Strata treningowa: 0.6845024870446883\n",
      "Strata walidacyjna po epoce: 0.7749698512744159\n",
      "Epoka [8/10], Strata treningowa: 0.6250281061630696\n",
      "Epoka [9/10], Strata treningowa: 0.5678853725056268\n",
      "Epoka [10/10], Strata treningowa: 0.5217817104377201\n",
      "Strata walidacyjna po epoce: 0.7236379131372087\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6833288888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 20:55:38,035] Trial 31 finished with value: 0.7519 and parameters: {'lr': 0.0003980452871284118, 'n_layers': 4, 'conv_out': 96, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 186294\n",
      "Epoka [1/10], Strata treningowa: 1.757629832148552\n",
      "Strata walidacyjna po epoce: 1.563619505929947\n",
      "Epoka [2/10], Strata treningowa: 1.4779608553912904\n",
      "Epoka [3/10], Strata treningowa: 1.3424595749206014\n",
      "Epoka [4/10], Strata treningowa: 1.2408087250245943\n",
      "Strata walidacyjna po epoce: 1.2072428828954698\n",
      "Epoka [5/10], Strata treningowa: 1.1647162103248967\n",
      "Epoka [6/10], Strata treningowa: 1.0967416448341476\n",
      "Epoka [7/10], Strata treningowa: 1.0381540846983592\n",
      "Strata walidacyjna po epoce: 1.02637228512913\n",
      "Epoka [8/10], Strata treningowa: 0.984183240133524\n",
      "Epoka [9/10], Strata treningowa: 0.9372411299420728\n",
      "Epoka [10/10], Strata treningowa: 0.8951221094083455\n",
      "Strata walidacyjna po epoce: 0.9323459298789502\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5682022222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 21:05:02,855] Trial 32 finished with value: 0.6661 and parameters: {'lr': 0.00013498638277800376, 'n_layers': 4, 'conv_out': 80, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 353174\n",
      "Epoka [1/10], Strata treningowa: 1.5679681467294693\n",
      "Strata walidacyjna po epoce: 1.364069206905365\n",
      "Epoka [2/10], Strata treningowa: 1.199854257498847\n",
      "Epoka [3/10], Strata treningowa: 1.0007997427198623\n",
      "Epoka [4/10], Strata treningowa: 0.862642086947047\n",
      "Strata walidacyjna po epoce: 0.8515301269292831\n",
      "Epoka [5/10], Strata treningowa: 0.7593811693558262\n",
      "Epoka [6/10], Strata treningowa: 0.6770932468346734\n",
      "Epoka [7/10], Strata treningowa: 0.6031493830004087\n",
      "Strata walidacyjna po epoce: 0.7159567658279091\n",
      "Epoka [8/10], Strata treningowa: 0.5399511945991052\n",
      "Epoka [9/10], Strata treningowa: 0.4827412773814544\n",
      "Epoka [10/10], Strata treningowa: 0.43243241810986527\n",
      "Strata walidacyjna po epoce: 0.7265187840498053\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.70922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 21:17:27,625] Trial 33 finished with value: 0.7616 and parameters: {'lr': 0.00041634670273854536, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 262822\n",
      "Epoka [1/10], Strata treningowa: 1.5614968458215395\n",
      "Strata walidacyjna po epoce: 1.2469090716779232\n",
      "Epoka [2/10], Strata treningowa: 1.168894184491866\n",
      "Epoka [3/10], Strata treningowa: 0.995958933290922\n",
      "Epoka [4/10], Strata treningowa: 0.8720158757672541\n",
      "Strata walidacyjna po epoce: 0.9036111782759428\n",
      "Epoka [5/10], Strata treningowa: 0.7784255319127813\n",
      "Epoka [6/10], Strata treningowa: 0.6959871109317833\n",
      "Epoka [7/10], Strata treningowa: 0.6280540576731353\n",
      "Strata walidacyjna po epoce: 0.7645179371636361\n",
      "Epoka [8/10], Strata treningowa: 0.574409126120472\n",
      "Epoka [9/10], Strata treningowa: 0.5223905963739267\n",
      "Epoka [10/10], Strata treningowa: 0.4782809853342132\n",
      "Strata walidacyjna po epoce: 0.7452398239700123\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7052666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 21:28:04,112] Trial 34 finished with value: 0.7374 and parameters: {'lr': 0.000720130698550984, 'n_layers': 4, 'conv_out': 96, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 179782\n",
      "Epoka [1/10], Strata treningowa: 1.500046082593335\n",
      "Strata walidacyjna po epoce: 1.2688567053079605\n",
      "Epoka [2/10], Strata treningowa: 1.1724129179186291\n",
      "Epoka [3/10], Strata treningowa: 1.0194382645673221\n",
      "Epoka [4/10], Strata treningowa: 0.9205491085679167\n",
      "Strata walidacyjna po epoce: 0.9245539968699217\n",
      "Epoka [5/10], Strata treningowa: 0.8452934307900775\n",
      "Epoka [6/10], Strata treningowa: 0.7857092655652927\n",
      "Epoka [7/10], Strata treningowa: 0.7425925234403513\n",
      "Strata walidacyjna po epoce: 0.8736022232696414\n",
      "Epoka [8/10], Strata treningowa: 0.7071826553077023\n",
      "Epoka [9/10], Strata treningowa: 0.6709562066288044\n",
      "Epoka [10/10], Strata treningowa: 0.6428352420782489\n",
      "Strata walidacyjna po epoce: 0.8506166192902253\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6790422222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 21:37:45,664] Trial 35 finished with value: 0.7085 and parameters: {'lr': 0.0012483840073070805, 'n_layers': 3, 'conv_out': 96, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 186294\n",
      "Epoka [1/10], Strata treningowa: 1.7170317393276426\n",
      "Strata walidacyjna po epoce: 1.5097314638614654\n",
      "Epoka [2/10], Strata treningowa: 1.4014232996212113\n",
      "Epoka [3/10], Strata treningowa: 1.2614878086752361\n",
      "Epoka [4/10], Strata treningowa: 1.1578838708970283\n",
      "Strata walidacyjna po epoce: 1.1303598345756531\n",
      "Epoka [5/10], Strata treningowa: 1.0658319375144112\n",
      "Epoka [6/10], Strata treningowa: 0.9847591568554441\n",
      "Epoka [7/10], Strata treningowa: 0.9216813724997143\n",
      "Strata walidacyjna po epoce: 0.9872296660006046\n",
      "Epoka [8/10], Strata treningowa: 0.8661095404803753\n",
      "Epoka [9/10], Strata treningowa: 0.8173603889033199\n",
      "Epoka [10/10], Strata treningowa: 0.7705792535627054\n",
      "Strata walidacyjna po epoce: 0.9195823829790577\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6038111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 21:47:04,909] Trial 36 finished with value: 0.6833 and parameters: {'lr': 0.00018353712769913737, 'n_layers': 4, 'conv_out': 80, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 457350\n",
      "Epoka [1/10], Strata treningowa: 1.7341651399003135\n",
      "Strata walidacyjna po epoce: 1.5440374624013902\n",
      "Epoka [2/10], Strata treningowa: 1.4708209624237485\n",
      "Epoka [3/10], Strata treningowa: 1.3478881508191427\n",
      "Epoka [4/10], Strata treningowa: 1.253297124601735\n",
      "Strata walidacyjna po epoce: 1.2228294064819814\n",
      "Epoka [5/10], Strata treningowa: 1.1726867410699526\n",
      "Epoka [6/10], Strata treningowa: 1.1050372994985844\n",
      "Epoka [7/10], Strata treningowa: 1.0443649396684436\n",
      "Strata walidacyjna po epoce: 1.0653962825477123\n",
      "Epoka [8/10], Strata treningowa: 0.9924570009039508\n",
      "Epoka [9/10], Strata treningowa: 0.9460616181251076\n",
      "Epoka [10/10], Strata treningowa: 0.9043372161795695\n",
      "Strata walidacyjna po epoce: 0.9294500075429678\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5682933333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 21:59:35,854] Trial 37 finished with value: 0.663 and parameters: {'lr': 9.02937973644179e-05, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 466182\n",
      "Epoka [1/10], Strata treningowa: 1.664772975054052\n",
      "Strata walidacyjna po epoce: 1.399080805683136\n",
      "Epoka [2/10], Strata treningowa: 1.230386314370566\n",
      "Epoka [3/10], Strata treningowa: 1.0231581484469274\n",
      "Epoka [4/10], Strata treningowa: 0.8865751225012872\n",
      "Strata walidacyjna po epoce: 0.8980901614792645\n",
      "Epoka [5/10], Strata treningowa: 0.7775736442298732\n",
      "Epoka [6/10], Strata treningowa: 0.6933854330033633\n",
      "Epoka [7/10], Strata treningowa: 0.62250171104251\n",
      "Strata walidacyjna po epoce: 0.7382182333046571\n",
      "Epoka [8/10], Strata treningowa: 0.5563391757068367\n",
      "Epoka [9/10], Strata treningowa: 0.5002430379985696\n",
      "Epoka [10/10], Strata treningowa: 0.45115488241549273\n",
      "Strata walidacyjna po epoce: 0.7657205868508318\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6983977777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 22:13:01,397] Trial 38 finished with value: 0.7451 and parameters: {'lr': 0.0006238747315416307, 'n_layers': 5, 'conv_out': 112, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 80, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 30774\n",
      "Epoka [1/10], Strata treningowa: 1.9327555253982545\n",
      "Strata walidacyjna po epoce: 1.8318781203508376\n",
      "Epoka [2/10], Strata treningowa: 1.7652868767393959\n",
      "Epoka [3/10], Strata treningowa: 1.6881161404106353\n",
      "Epoka [4/10], Strata treningowa: 1.6400261477549871\n",
      "Strata walidacyjna po epoce: 1.6489119596242905\n",
      "Epoka [5/10], Strata treningowa: 1.6029185990307067\n",
      "Epoka [6/10], Strata treningowa: 1.5742012152751286\n",
      "Epoka [7/10], Strata treningowa: 1.549445103544659\n",
      "Strata walidacyjna po epoce: 1.5591993507623672\n",
      "Epoka [8/10], Strata treningowa: 1.5293878168437216\n",
      "Epoka [9/10], Strata treningowa: 1.5115596723331346\n",
      "Epoka [10/10], Strata treningowa: 1.4957960077087085\n",
      "Strata walidacyjna po epoce: 1.5405520477294923\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.4064844444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 22:21:05,024] Trial 39 finished with value: 0.4572 and parameters: {'lr': 0.0003812335676403082, 'n_layers': 4, 'conv_out': 80, 'kernel_size': 1}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-2): 2 x Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 179782\n",
      "Epoka [1/10], Strata treningowa: 1.4925588277710808\n",
      "Strata walidacyjna po epoce: 1.2914470352888108\n",
      "Epoka [2/10], Strata treningowa: 1.1889000293337637\n",
      "Epoka [3/10], Strata treningowa: 1.0484345756206248\n",
      "Epoka [4/10], Strata treningowa: 0.9486436781064503\n",
      "Strata walidacyjna po epoce: 0.9700464186802507\n",
      "Epoka [5/10], Strata treningowa: 0.8858083159285287\n",
      "Epoka [6/10], Strata treningowa: 0.8260403163771042\n",
      "Epoka [7/10], Strata treningowa: 0.7756500810209869\n",
      "Strata walidacyjna po epoce: 0.9077428590934724\n",
      "Epoka [8/10], Strata treningowa: 0.7429850358672285\n",
      "Epoka [9/10], Strata treningowa: 0.7051354631864672\n",
      "Epoka [10/10], Strata treningowa: 0.6730639961298607\n",
      "Strata walidacyjna po epoce: 0.8883102974047884\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6688622222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 22:30:40,493] Trial 40 finished with value: 0.6999 and parameters: {'lr': 0.001242971720351592, 'n_layers': 3, 'conv_out': 96, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(112, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 960662\n",
      "Epoka [1/10], Strata treningowa: 1.5501713074445724\n",
      "Strata walidacyjna po epoce: 1.3280042218565942\n",
      "Epoka [2/10], Strata treningowa: 1.1374845430523157\n",
      "Epoka [3/10], Strata treningowa: 0.9215198325040854\n",
      "Epoka [4/10], Strata treningowa: 0.7664938607777573\n",
      "Strata walidacyjna po epoce: 0.8160243333041668\n",
      "Epoka [5/10], Strata treningowa: 0.6539438231559496\n",
      "Epoka [6/10], Strata treningowa: 0.561648800416512\n",
      "Epoka [7/10], Strata treningowa: 0.47549810011880084\n",
      "Strata walidacyjna po epoce: 0.7495841654911637\n",
      "Epoka [8/10], Strata treningowa: 0.4008255069742095\n",
      "Epoka [9/10], Strata treningowa: 0.33017768375236073\n",
      "Epoka [10/10], Strata treningowa: 0.2720279926250624\n",
      "Strata walidacyjna po epoce: 0.9108516426654066\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7488888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 22:47:31,256] Trial 41 finished with value: 0.7539 and parameters: {'lr': 0.00039006596870042753, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 5}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 457350\n",
      "Epoka [1/10], Strata treningowa: 1.6012714306407505\n",
      "Strata walidacyjna po epoce: 1.3631849974870682\n",
      "Epoka [2/10], Strata treningowa: 1.2449038755178452\n",
      "Epoka [3/10], Strata treningowa: 1.0705062495830986\n",
      "Epoka [4/10], Strata treningowa: 0.9400811292560565\n",
      "Strata walidacyjna po epoce: 0.9364678833633662\n",
      "Epoka [5/10], Strata treningowa: 0.8406581482229133\n",
      "Epoka [6/10], Strata treningowa: 0.7568210156265647\n",
      "Epoka [7/10], Strata treningowa: 0.6834072658727567\n",
      "Strata walidacyjna po epoce: 0.7624367477431894\n",
      "Epoka [8/10], Strata treningowa: 0.6181468012688267\n",
      "Epoka [9/10], Strata treningowa: 0.5584616176862502\n",
      "Epoka [10/10], Strata treningowa: 0.5077124009883394\n",
      "Strata walidacyjna po epoce: 0.6828370176147204\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6837288888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 23:01:28,966] Trial 42 finished with value: 0.7566 and parameters: {'lr': 0.00025058057710034226, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3}. Best is trial 23 with value: 0.7618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 1249926\n",
      "Epoka [1/10], Strata treningowa: 1.6030388428542348\n",
      "Strata walidacyjna po epoce: 1.3431966041326522\n",
      "Epoka [2/10], Strata treningowa: 1.2340994815968804\n",
      "Epoka [3/10], Strata treningowa: 1.0421021616786719\n",
      "Epoka [4/10], Strata treningowa: 0.9019348129370146\n",
      "Strata walidacyjna po epoce: 0.882915708707273\n",
      "Epoka [5/10], Strata treningowa: 0.7974806307367981\n",
      "Epoka [6/10], Strata treningowa: 0.6983017766169997\n",
      "Epoka [7/10], Strata treningowa: 0.6171529193612177\n",
      "Strata walidacyjna po epoce: 0.7271851681066677\n",
      "Epoka [8/10], Strata treningowa: 0.5443386938263818\n",
      "Epoka [9/10], Strata treningowa: 0.4775664931629629\n",
      "Epoka [10/10], Strata treningowa: 0.41277746621546946\n",
      "Strata walidacyjna po epoce: 0.6964347420522011\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 23:20:42,876] Trial 43 finished with value: 0.7641 and parameters: {'lr': 0.00013353402447959808, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 5}. Best is trial 43 with value: 0.7641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 457350\n",
      "Epoka [1/10], Strata treningowa: 1.6866980683724087\n",
      "Strata walidacyjna po epoce: 1.4571725982666015\n",
      "Epoka [2/10], Strata treningowa: 1.3739850796580315\n",
      "Epoka [3/10], Strata treningowa: 1.2391688437518147\n",
      "Epoka [4/10], Strata treningowa: 1.134413085499737\n",
      "Strata walidacyjna po epoce: 1.1091588140368462\n",
      "Epoka [5/10], Strata treningowa: 1.041051423369017\n",
      "Epoka [6/10], Strata treningowa: 0.9620109543098344\n",
      "Epoka [7/10], Strata treningowa: 0.8980653491841423\n",
      "Strata walidacyjna po epoce: 0.9329880600273609\n",
      "Epoka [8/10], Strata treningowa: 0.8399775401591427\n",
      "Epoka [9/10], Strata treningowa: 0.7902784850450854\n",
      "Epoka [10/10], Strata treningowa: 0.7410717323493833\n",
      "Strata walidacyjna po epoce: 0.8043156056128442\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.6148111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 23:33:13,599] Trial 44 finished with value: 0.7078 and parameters: {'lr': 0.0001267297990974149, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3}. Best is trial 43 with value: 0.7641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 457350\n",
      "Epoka [1/10], Strata treningowa: 1.8042808542781406\n",
      "Strata walidacyjna po epoce: 1.6830530431747437\n",
      "Epoka [2/10], Strata treningowa: 1.551170001914766\n",
      "Epoka [3/10], Strata treningowa: 1.4428632026169035\n",
      "Epoka [4/10], Strata treningowa: 1.3657164524912835\n",
      "Strata walidacyjna po epoce: 1.3845882234811784\n",
      "Epoka [5/10], Strata treningowa: 1.3004048421965706\n",
      "Epoka [6/10], Strata treningowa: 1.2398494242290656\n",
      "Epoka [7/10], Strata treningowa: 1.1828391950494712\n",
      "Strata walidacyjna po epoce: 1.2095744770646095\n",
      "Epoka [8/10], Strata treningowa: 1.1329663780662749\n",
      "Epoka [9/10], Strata treningowa: 1.0856196697109275\n",
      "Epoka [10/10], Strata treningowa: 1.0425554202497005\n",
      "Strata walidacyjna po epoce: 1.0630909684181213\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5234444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-24 23:45:13,138] Trial 45 finished with value: 0.6226 and parameters: {'lr': 6.33097904088287e-05, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3}. Best is trial 43 with value: 0.7641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 1659654\n",
      "Epoka [1/10], Strata treningowa: 1.679342135075728\n",
      "Strata walidacyjna po epoce: 1.4602538145542145\n",
      "Epoka [2/10], Strata treningowa: 1.2644271383103398\n",
      "Epoka [3/10], Strata treningowa: 1.0256453419861695\n",
      "Epoka [4/10], Strata treningowa: 0.8684884107621593\n",
      "Strata walidacyjna po epoce: 0.842139048445411\n",
      "Epoka [5/10], Strata treningowa: 0.7437421527185218\n",
      "Epoka [6/10], Strata treningowa: 0.6353160919748532\n",
      "Epoka [7/10], Strata treningowa: 0.5441426522422582\n",
      "Strata walidacyjna po epoce: 0.7089168999038636\n",
      "Epoka [8/10], Strata treningowa: 0.4573930559686388\n",
      "Epoka [9/10], Strata treningowa: 0.37816696466149763\n",
      "Epoka [10/10], Strata treningowa: 0.3114862585423832\n",
      "Strata walidacyjna po epoce: 0.7926350839102201\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7164488888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 08:08:50,372] Trial 46 finished with value: 0.7519 and parameters: {'lr': 0.00024321015993684854, 'n_layers': 5, 'conv_out': 128, 'kernel_size': 5}. Best is trial 43 with value: 0.7641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 90342\n",
      "Epoka [1/10], Strata treningowa: 1.7534592794100443\n",
      "Strata walidacyjna po epoce: 1.583005232191086\n",
      "Epoka [2/10], Strata treningowa: 1.4874737862375047\n",
      "Epoka [3/10], Strata treningowa: 1.347038008403778\n",
      "Epoka [4/10], Strata treningowa: 1.238210235382451\n",
      "Strata walidacyjna po epoce: 1.2629875237584114\n",
      "Epoka [5/10], Strata treningowa: 1.1449564685030116\n",
      "Epoka [6/10], Strata treningowa: 1.0603128716028398\n",
      "Epoka [7/10], Strata treningowa: 0.9898379220563505\n",
      "Strata walidacyjna po epoce: 0.9731487642765045\n",
      "Epoka [8/10], Strata treningowa: 0.9316191514737077\n",
      "Epoka [9/10], Strata treningowa: 0.8791689483116071\n",
      "Epoka [10/10], Strata treningowa: 0.8343670993278424\n",
      "Strata walidacyjna po epoce: 0.8644286892615258\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.5776688888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 08:14:49,881] Trial 47 finished with value: 0.6926 and parameters: {'lr': 0.00015404661475185594, 'n_layers': 4, 'conv_out': 32, 'kernel_size': 5}. Best is trial 43 with value: 0.7641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 604934\n",
      "Epoka [1/10], Strata treningowa: 1.63876090695858\n",
      "Strata walidacyjna po epoce: 1.3417034246206283\n",
      "Epoka [2/10], Strata treningowa: 1.1992945518407556\n",
      "Epoka [3/10], Strata treningowa: 0.9847951352911691\n",
      "Epoka [4/10], Strata treningowa: 0.8435952711148395\n",
      "Strata walidacyjna po epoce: 0.8304624155700207\n",
      "Epoka [5/10], Strata treningowa: 0.7345055282804701\n",
      "Epoka [6/10], Strata treningowa: 0.6479134633668905\n",
      "Epoka [7/10], Strata treningowa: 0.5701964628337248\n",
      "Strata walidacyjna po epoce: 0.7065733222015901\n",
      "Epoka [8/10], Strata treningowa: 0.5001991213685616\n",
      "Epoka [9/10], Strata treningowa: 0.4391367827676351\n",
      "Epoka [10/10], Strata treningowa: 0.38483419682881786\n",
      "Strata walidacyjna po epoce: 0.7258881696552969\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7148288888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 08:28:39,746] Trial 48 finished with value: 0.7606 and parameters: {'lr': 0.0006335240259183046, 'n_layers': 5, 'conv_out': 128, 'kernel_size': 3}. Best is trial 43 with value: 0.7641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "    (1-4): 4 x Conv2d(112, 112, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 466182\n",
      "Epoka [1/10], Strata treningowa: 1.6370123404542605\n",
      "Strata walidacyjna po epoce: 1.339691063451767\n",
      "Epoka [2/10], Strata treningowa: 1.1910895387404494\n",
      "Epoka [3/10], Strata treningowa: 0.976953160471345\n",
      "Epoka [4/10], Strata treningowa: 0.8393579106605301\n",
      "Strata walidacyjna po epoce: 0.867529459670186\n",
      "Epoka [5/10], Strata treningowa: 0.737253343173132\n",
      "Epoka [6/10], Strata treningowa: 0.6563363448296363\n",
      "Epoka [7/10], Strata treningowa: 0.5830366153113647\n",
      "Strata walidacyjna po epoce: 0.7127059815961868\n",
      "Epoka [8/10], Strata treningowa: 0.5241961216239246\n",
      "Epoka [9/10], Strata treningowa: 0.47369877145720124\n",
      "Epoka [10/10], Strata treningowa: 0.42269756067514636\n",
      "Strata walidacyjna po epoce: 0.7932246393388734\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7112111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 08:41:10,613] Trial 49 finished with value: 0.7482 and parameters: {'lr': 0.0007890608620311848, 'n_layers': 5, 'conv_out': 112, 'kernel_size': 3}. Best is trial 43 with value: 0.7641.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze hiperparametry:  {'lr': 0.00013353402447959808, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 5}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Najlepsze hiperparametry: \", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wykorzystanie hiperparametrów zwróconych przez Optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 1249926\n",
      "Epoka [1/10], Strata treningowa: 1.5983011417852508\n",
      "Strata walidacyjna po epoce: 1.3356838511943818\n",
      "Epoka [2/10], Strata treningowa: 1.2073228071563773\n",
      "Epoka [3/10], Strata treningowa: 0.999745543134378\n",
      "Epoka [4/10], Strata treningowa: 0.8593897186319447\n",
      "Strata walidacyjna po epoce: 0.8396822881504893\n",
      "Epoka [5/10], Strata treningowa: 0.7452004166583635\n",
      "Epoka [6/10], Strata treningowa: 0.6545320023488771\n",
      "Epoka [7/10], Strata treningowa: 0.5765337354906576\n",
      "Strata walidacyjna po epoce: 0.6959203270178288\n",
      "Epoka [8/10], Strata treningowa: 0.5037861454367689\n",
      "Epoka [9/10], Strata treningowa: 0.43553089056132077\n",
      "Epoka [10/10], Strata treningowa: 0.3735848239121642\n",
      "Strata walidacyjna po epoce: 0.689738870471064\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7148488888888889\n",
      "Accuracy with best hyperparameters: 0.7688\n"
     ]
    }
   ],
   "source": [
    "best_layers = [\n",
    "    {\"entry\": 3, \"out\": 128, \"kernel_size\": 5}\n",
    "]\n",
    "for _ in range(4 - 1):\n",
    "    best_layers.append({\"entry\": 128, \"out\": 128, \"kernel_size\": 5})\n",
    "\n",
    "accuracy = custom_net(lerning_late=0.00013353402447959808, layers=best_layers, num_epochs=10)\n",
    "print(f'Accuracy with best hyperparameters: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ulepszony model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Custom_With_Tricks(nn.Module):\n",
    "    def __init__(self, layers, dropout_probability, fc1_neurons = 120, fc2_neurons = 84, input_size=(32, 32)) -> None:\n",
    "        super(Model_Custom_With_Tricks, self).__init__()\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(layers[i][\"entry\"], layers[i][\"out\"], kernel_size=layers[i][\"kernel_size\"], stride=1, padding=2) for i in range(len(layers))])\n",
    "        self.pool = nn.AvgPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout2d(p=dropout_probability)\n",
    "\n",
    "        self.fc1 = None\n",
    "        self.fc1_in_neurons = fc1_neurons\n",
    "        self.fc2 = nn.Linear(fc1_neurons, fc2_neurons)\n",
    "        self.fc_last = nn.Linear(fc2_neurons, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for conv in self.convs:\n",
    "            x = F.relu(self.dropout(conv(x)))\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        if self.fc1 is None:\n",
    "            in_features = x.size(1)\n",
    "            self.fc1 = nn.Linear(in_features, self.fc1_in_neurons)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc_last(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ulepszony trening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_net_with_tricks(lerning_late, layers, num_epochs, dropout_probability, reg_l2, fc1_neurons, fc2_neurons):\n",
    "    model = Model_Custom_With_Tricks(layers, dropout_probability, fc1_neurons, fc2_neurons)\n",
    "    # print(model)\n",
    "    # print(f\"Liczba parametrów modelu: {count_parameters(model)}\")\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lerning_late, weight_decay=reg_l2)\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=lerning_late)\n",
    "    total_correct = 0\n",
    "    total_samples = 0 \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            output_loss = loss(output, labels)\n",
    "            output_loss.backward()  \n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "            running_loss += output_loss.item()\n",
    "\n",
    "        # print(f'Epoka [{epoch+1}/{num_epochs}], Strata treningowa: {running_loss/len(trainloader)}')\n",
    "\n",
    "        if (epoch % 3 == 0):\n",
    "            model.eval()\n",
    "            validation_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_images, val_labels in valloader:\n",
    "                    val_output = model(val_images)\n",
    "                    val_loss = loss(val_output, val_labels)\n",
    "                    validation_loss += val_loss.item()\n",
    "\n",
    "            # print(f'Strata walidacyjna po epoce: {validation_loss/len(valloader)}')\n",
    "            model.train()\n",
    "\n",
    "    # print(f'\\nWynik dokładności dla mojego modelu dla danych treningowych: {total_correct / total_samples}')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_correct = 0\n",
    "    test_samples = 0 \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct = (predicted == labels).sum().item()\n",
    "            test_correct += correct\n",
    "            test_samples += labels.size(0)\n",
    "    \n",
    "        print(f'\\nWynik dokładności dla mojego modelu dla danych testowych: {test_correct / test_samples}')\n",
    "\n",
    "    return test_correct / test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_with_tricks(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    conv_out_init = trial.suggest_int('conv_out', 8, 128, step=8)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 1, 5, step=1)\n",
    "    dropout_probability = trial.suggest_loguniform('p', 1e-5, 0.5)\n",
    "    reg_l2 = trial.suggest_loguniform('weight_decay', 1e-5, 0.5)\n",
    "    fc1_neurons = trial.suggest_int('fc1_neurons', 50, 200, step=2)\n",
    "    fc2_neurons = trial.suggest_int('fc2_neurons', 50, 200, step=2)\n",
    "\n",
    "    layers = [\n",
    "        {\"entry\": 3, \"out\": conv_out_init, \"kernel_size\": kernel_size}\n",
    "    ]\n",
    "    for _ in range(n_layers - 1):\n",
    "        conv_out = trial.suggest_int('conv_out', 8, 128, step=8)\n",
    "        layers.append({\"entry\": conv_out_init, \"out\": conv_out, \"kernel_size\": kernel_size})\n",
    "        conv_out_init = conv_out\n",
    "\n",
    "    accuracy = custom_net_with_tricks(lr, layers, num_epochs=10, dropout_probability=dropout_probability, reg_l2=reg_l2, fc1_neurons=fc1_neurons, fc2_neurons=fc2_neurons)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:24:11,607] A new study created in memory with name: no-name-16868935-0372-435e-9201-44a080f592c1\n",
      "C:\\Users\\Mateusz\\AppData\\Local\\Temp\\ipykernel_3548\\3207235672.py:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
      "C:\\Users\\Mateusz\\AppData\\Local\\Temp\\ipykernel_3548\\3207235672.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  dropout_probability = trial.suggest_loguniform('p', 1e-5, 0.5)\n",
      "C:\\Users\\Mateusz\\AppData\\Local\\Temp\\ipykernel_3548\\3207235672.py:7: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  reg_l2 = trial.suggest_loguniform('weight_decay', 1e-5, 0.5)\n",
      "[I 2024-10-25 15:30:56,209] Trial 0 finished with value: 0.4732 and parameters: {'lr': 9.77709044293636e-05, 'n_layers': 5, 'conv_out': 24, 'kernel_size': 3, 'p': 0.0011285347569475969, 'weight_decay': 0.0003049766908058696, 'fc1_neurons': 152, 'fc2_neurons': 120}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.4732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:41:39,381] Trial 1 finished with value: 0.1 and parameters: {'lr': 0.0008077662979191951, 'n_layers': 4, 'conv_out': 80, 'kernel_size': 5, 'p': 0.0001143702066970796, 'weight_decay': 0.041088339883503626, 'fc1_neurons': 138, 'fc2_neurons': 196}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:46:50,907] Trial 2 finished with value: 0.1 and parameters: {'lr': 2.2134387272326548e-05, 'n_layers': 5, 'conv_out': 8, 'kernel_size': 1, 'p': 3.311333661501753e-05, 'weight_decay': 0.006289041696040738, 'fc1_neurons': 130, 'fc2_neurons': 200}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 15:55:32,308] Trial 3 finished with value: 0.1 and parameters: {'lr': 0.0004175367060202826, 'n_layers': 5, 'conv_out': 88, 'kernel_size': 1, 'p': 0.00556213290244178, 'weight_decay': 0.0005186208516663984, 'fc1_neurons': 68, 'fc2_neurons': 152}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 16:03:29,774] Trial 4 finished with value: 0.1 and parameters: {'lr': 2.0664609144715274e-05, 'n_layers': 4, 'conv_out': 56, 'kernel_size': 4, 'p': 0.04252040274805366, 'weight_decay': 0.11901749666702068, 'fc1_neurons': 164, 'fc2_neurons': 94}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 16:10:44,205] Trial 5 finished with value: 0.1 and parameters: {'lr': 0.0009111605840789583, 'n_layers': 3, 'conv_out': 64, 'kernel_size': 2, 'p': 0.015115881256933304, 'weight_decay': 0.010666605694766601, 'fc1_neurons': 140, 'fc2_neurons': 66}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 16:27:13,670] Trial 6 finished with value: 0.1 and parameters: {'lr': 0.0007620135776657592, 'n_layers': 5, 'conv_out': 112, 'kernel_size': 5, 'p': 7.54283826342938e-05, 'weight_decay': 0.0032961199471372832, 'fc1_neurons': 174, 'fc2_neurons': 110}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 16:34:38,562] Trial 7 finished with value: 0.3846 and parameters: {'lr': 8.218848900471601e-05, 'n_layers': 2, 'conv_out': 128, 'kernel_size': 1, 'p': 4.5314264876634386e-05, 'weight_decay': 0.004501833439356838, 'fc1_neurons': 140, 'fc2_neurons': 66}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.3846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 16:44:08,666] Trial 8 finished with value: 0.1 and parameters: {'lr': 0.005527818550273257, 'n_layers': 5, 'conv_out': 72, 'kernel_size': 3, 'p': 0.49007742928075665, 'weight_decay': 0.14381807695622442, 'fc1_neurons': 78, 'fc2_neurons': 166}. Best is trial 0 with value: 0.4732.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 16:51:05,274] Trial 9 finished with value: 0.6667 and parameters: {'lr': 0.000899351961419249, 'n_layers': 5, 'conv_out': 32, 'kernel_size': 5, 'p': 0.00016113654792354303, 'weight_decay': 8.475394520986537e-05, 'fc1_neurons': 134, 'fc2_neurons': 68}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 16:57:00,685] Trial 10 finished with value: 0.1 and parameters: {'lr': 0.006905764789417969, 'n_layers': 3, 'conv_out': 40, 'kernel_size': 4, 'p': 0.0005972216462672624, 'weight_decay': 1.3480863236292702e-05, 'fc1_neurons': 100, 'fc2_neurons': 56}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:02:01,126] Trial 11 finished with value: 0.4505 and parameters: {'lr': 0.00011685593638324444, 'n_layers': 4, 'conv_out': 8, 'kernel_size': 3, 'p': 0.0006832236115726169, 'weight_decay': 0.0001735276187898918, 'fc1_neurons': 194, 'fc2_neurons': 130}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.4505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:08:45,582] Trial 12 finished with value: 0.5874 and parameters: {'lr': 0.0001259173854084797, 'n_layers': 5, 'conv_out': 32, 'kernel_size': 4, 'p': 0.0007317915333507134, 'weight_decay': 5.182908828891872e-05, 'fc1_neurons': 100, 'fc2_neurons': 88}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.5874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:15:42,110] Trial 13 finished with value: 0.6214 and parameters: {'lr': 0.002899339498199372, 'n_layers': 4, 'conv_out': 40, 'kernel_size': 4, 'p': 0.0001950765547707615, 'weight_decay': 1.4499983511494896e-05, 'fc1_neurons': 104, 'fc2_neurons': 86}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:23:08,997] Trial 14 finished with value: 0.6114 and parameters: {'lr': 0.0023811902961206233, 'n_layers': 4, 'conv_out': 48, 'kernel_size': 5, 'p': 0.00018327235960238653, 'weight_decay': 1.2732147216988823e-05, 'fc1_neurons': 108, 'fc2_neurons': 86}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:28:15,240] Trial 15 finished with value: 0.6324 and parameters: {'lr': 0.002202380958407891, 'n_layers': 3, 'conv_out': 24, 'kernel_size': 4, 'p': 1.3193675306265801e-05, 'weight_decay': 5.523767179586409e-05, 'fc1_neurons': 50, 'fc2_neurons': 50}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:32:42,702] Trial 16 finished with value: 0.5945 and parameters: {'lr': 0.001842862821566338, 'n_layers': 2, 'conv_out': 24, 'kernel_size': 5, 'p': 1.1282371324806874e-05, 'weight_decay': 9.645527974543985e-05, 'fc1_neurons': 56, 'fc2_neurons': 50}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.5945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:37:11,380] Trial 17 finished with value: 0.37 and parameters: {'lr': 0.009531092274487108, 'n_layers': 3, 'conv_out': 16, 'kernel_size': 4, 'p': 1.982641579528666e-05, 'weight_decay': 0.0008101022263547097, 'fc1_neurons': 114, 'fc2_neurons': 72}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:46:28,197] Trial 18 finished with value: 0.6351 and parameters: {'lr': 0.00027867899975849645, 'n_layers': 3, 'conv_out': 96, 'kernel_size': 2, 'p': 1.1254769046100532e-05, 'weight_decay': 5.7258690725788374e-05, 'fc1_neurons': 88, 'fc2_neurons': 104}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 17:54:30,145] Trial 19 finished with value: 0.5319 and parameters: {'lr': 0.0002334959386041964, 'n_layers': 2, 'conv_out': 104, 'kernel_size': 2, 'p': 0.0027697525037340184, 'weight_decay': 0.001314098893547152, 'fc1_neurons': 90, 'fc2_neurons': 104}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.5319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 18:03:07,772] Trial 20 finished with value: 0.6601 and parameters: {'lr': 0.0003403965675180744, 'n_layers': 3, 'conv_out': 88, 'kernel_size': 2, 'p': 0.00029500930043306, 'weight_decay': 3.846112115195457e-05, 'fc1_neurons': 78, 'fc2_neurons': 140}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 18:11:46,821] Trial 21 finished with value: 0.655 and parameters: {'lr': 0.0003131347218493363, 'n_layers': 3, 'conv_out': 88, 'kernel_size': 2, 'p': 0.00023607908798514373, 'weight_decay': 3.988660965462927e-05, 'fc1_neurons': 82, 'fc2_neurons': 136}. Best is trial 9 with value: 0.6667.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 18:19:57,054] Trial 22 finished with value: 0.6806 and parameters: {'lr': 0.00046578791866016617, 'n_layers': 3, 'conv_out': 80, 'kernel_size': 2, 'p': 0.0002975189103190772, 'weight_decay': 2.7685580258337527e-05, 'fc1_neurons': 120, 'fc2_neurons': 142}. Best is trial 22 with value: 0.6806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 18:26:20,511] Trial 23 finished with value: 0.4839 and parameters: {'lr': 5.043369039053754e-05, 'n_layers': 2, 'conv_out': 72, 'kernel_size': 2, 'p': 0.0002574237469710106, 'weight_decay': 0.00019646955605036833, 'fc1_neurons': 128, 'fc2_neurons': 152}. Best is trial 22 with value: 0.6806.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 18:36:33,682] Trial 24 finished with value: 0.7373 and parameters: {'lr': 0.0005308679260355772, 'n_layers': 3, 'conv_out': 112, 'kernel_size': 3, 'p': 6.579081884505882e-05, 'weight_decay': 2.4910520936657625e-05, 'fc1_neurons': 118, 'fc2_neurons': 168}. Best is trial 24 with value: 0.7373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 18:49:28,997] Trial 25 finished with value: 0.73 and parameters: {'lr': 0.000992608368385913, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3, 'p': 7.903689732679999e-05, 'weight_decay': 0.00011996638904246466, 'fc1_neurons': 116, 'fc2_neurons': 178}. Best is trial 24 with value: 0.7373.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 19:02:20,617] Trial 26 finished with value: 0.7609 and parameters: {'lr': 0.0004887455587020212, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3, 'p': 8.355114506594244e-05, 'weight_decay': 2.344994663761095e-05, 'fc1_neurons': 118, 'fc2_neurons': 180}. Best is trial 26 with value: 0.7609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 19:15:11,743] Trial 27 finished with value: 0.7171 and parameters: {'lr': 0.0005817945394202284, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3, 'p': 5.5405705011297066e-05, 'weight_decay': 2.1913916720922512e-05, 'fc1_neurons': 120, 'fc2_neurons': 178}. Best is trial 26 with value: 0.7609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 19:28:02,866] Trial 28 finished with value: 0.705 and parameters: {'lr': 0.0014320224085144267, 'n_layers': 4, 'conv_out': 120, 'kernel_size': 3, 'p': 3.29978488284306e-05, 'weight_decay': 0.00014721201367342383, 'fc1_neurons': 156, 'fc2_neurons': 184}. Best is trial 26 with value: 0.7609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 19:39:26,248] Trial 29 finished with value: 0.6979 and parameters: {'lr': 0.0001671987375936343, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 3, 'p': 8.708944601279661e-05, 'weight_decay': 0.0003482997272257786, 'fc1_neurons': 114, 'fc2_neurons': 170}. Best is trial 26 with value: 0.7609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 19:52:01,928] Trial 30 finished with value: 0.4651 and parameters: {'lr': 0.0040222541011440864, 'n_layers': 4, 'conv_out': 120, 'kernel_size': 3, 'p': 0.0016319782925864755, 'weight_decay': 0.0014490494683181724, 'fc1_neurons': 150, 'fc2_neurons': 188}. Best is trial 26 with value: 0.7609.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.4651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 20:04:53,767] Trial 31 finished with value: 0.7648 and parameters: {'lr': 0.000558351467987026, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3, 'p': 4.8994094618860434e-05, 'weight_decay': 2.196737582857282e-05, 'fc1_neurons': 120, 'fc2_neurons': 170}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 20:17:54,239] Trial 32 finished with value: 0.7076 and parameters: {'lr': 0.001432166412707697, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3, 'p': 2.5379914725263744e-05, 'weight_decay': 2.509137290796118e-05, 'fc1_neurons': 124, 'fc2_neurons': 166}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 20:29:19,427] Trial 33 finished with value: 0.4451 and parameters: {'lr': 1.0094309816031244e-05, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 3, 'p': 7.145134377063391e-05, 'weight_decay': 0.00012686247822208082, 'fc1_neurons': 146, 'fc2_neurons': 156}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 20:42:06,455] Trial 34 finished with value: 0.7581 and parameters: {'lr': 0.0006677644552332527, 'n_layers': 4, 'conv_out': 120, 'kernel_size': 3, 'p': 0.00010213433083045227, 'weight_decay': 1.054145930974951e-05, 'fc1_neurons': 110, 'fc2_neurons': 190}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 20:55:30,216] Trial 35 finished with value: 0.1 and parameters: {'lr': 0.000577821036020308, 'n_layers': 4, 'conv_out': 104, 'kernel_size': 4, 'p': 2.1647346802015424e-05, 'weight_decay': 0.02035620909972798, 'fc1_neurons': 96, 'fc2_neurons': 200}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 21:06:59,170] Trial 36 finished with value: 0.6942 and parameters: {'lr': 0.00018749735317787563, 'n_layers': 3, 'conv_out': 120, 'kernel_size': 3, 'p': 0.00012710909340059545, 'weight_decay': 1.1915108558391286e-05, 'fc1_neurons': 108, 'fc2_neurons': 188}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 21:18:15,740] Trial 37 finished with value: 0.7546 and parameters: {'lr': 0.0005636637995239285, 'n_layers': 4, 'conv_out': 104, 'kernel_size': 3, 'p': 0.07277459746894985, 'weight_decay': 1.0330363445382415e-05, 'fc1_neurons': 128, 'fc2_neurons': 160}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 21:30:41,455] Trial 38 finished with value: 0.5788 and parameters: {'lr': 7.454073494282722e-05, 'n_layers': 5, 'conv_out': 104, 'kernel_size': 3, 'p': 0.18976602897999473, 'weight_decay': 1.0563998516769968e-05, 'fc1_neurons': 132, 'fc2_neurons': 158}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.5788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 21:45:21,059] Trial 39 finished with value: 0.1 and parameters: {'lr': 0.0014071219722963607, 'n_layers': 4, 'conv_out': 120, 'kernel_size': 4, 'p': 0.018830393993869928, 'weight_decay': 0.06877034111742346, 'fc1_neurons': 166, 'fc2_neurons': 194}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 21:54:22,068] Trial 40 finished with value: 0.4415 and parameters: {'lr': 0.0007402494955159149, 'n_layers': 5, 'conv_out': 96, 'kernel_size': 1, 'p': 0.007951812990577381, 'weight_decay': 2.0087034131491567e-05, 'fc1_neurons': 142, 'fc2_neurons': 180}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.4415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 22:05:53,918] Trial 41 finished with value: 0.1 and parameters: {'lr': 0.00040590916114827276, 'n_layers': 4, 'conv_out': 112, 'kernel_size': 3, 'p': 0.04395314369506338, 'weight_decay': 0.48837538050775486, 'fc1_neurons': 130, 'fc2_neurons': 170}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 22:18:41,917] Trial 42 finished with value: 0.7628 and parameters: {'lr': 0.0005699051053970612, 'n_layers': 4, 'conv_out': 120, 'kernel_size': 3, 'p': 4.524829784079318e-05, 'weight_decay': 2.9263071350237168e-05, 'fc1_neurons': 110, 'fc2_neurons': 162}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 22:31:37,883] Trial 43 finished with value: 0.7479 and parameters: {'lr': 0.0011096487042180953, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3, 'p': 0.05817839929983794, 'weight_decay': 3.7626999272148855e-05, 'fc1_neurons': 108, 'fc2_neurons': 148}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 22:44:28,852] Trial 44 finished with value: 0.7419 and parameters: {'lr': 0.00072288593460889, 'n_layers': 4, 'conv_out': 120, 'kernel_size': 3, 'p': 3.6536952588182804e-05, 'weight_decay': 7.359918599420426e-05, 'fc1_neurons': 126, 'fc2_neurons': 160}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 22:55:07,475] Trial 45 finished with value: 0.6411 and parameters: {'lr': 0.0002341650007889301, 'n_layers': 4, 'conv_out': 96, 'kernel_size': 2, 'p': 0.0004640344826507647, 'weight_decay': 0.00026299596045238676, 'fc1_neurons': 136, 'fc2_neurons': 194}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 23:08:48,895] Trial 46 finished with value: 0.7023 and parameters: {'lr': 0.00048346359931484255, 'n_layers': 5, 'conv_out': 128, 'kernel_size': 3, 'p': 0.28499936588595154, 'weight_decay': 1.0158730145014595e-05, 'fc1_neurons': 94, 'fc2_neurons': 174}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 23:22:13,824] Trial 47 finished with value: 0.7329 and parameters: {'lr': 0.0006802570192966933, 'n_layers': 4, 'conv_out': 104, 'kernel_size': 4, 'p': 0.0028944183301473506, 'weight_decay': 1.875824754396959e-05, 'fc1_neurons': 110, 'fc2_neurons': 126}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 23:34:49,212] Trial 48 finished with value: 0.7062 and parameters: {'lr': 0.00035028307372971115, 'n_layers': 4, 'conv_out': 120, 'kernel_size': 2, 'p': 0.0010475057117494493, 'weight_decay': 3.50450536254298e-05, 'fc1_neurons': 104, 'fc2_neurons': 192}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-25 23:49:23,259] Trial 49 finished with value: 0.6913 and parameters: {'lr': 0.0011728886074136727, 'n_layers': 5, 'conv_out': 112, 'kernel_size': 4, 'p': 0.0001188194790312498, 'weight_decay': 1.6356581626075445e-05, 'fc1_neurons': 124, 'fc2_neurons': 162}. Best is trial 31 with value: 0.7648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wynik dokładności dla mojego modelu dla danych testowych: 0.6913\n",
      "Najlepsze hiperparametry:  {'lr': 0.000558351467987026, 'n_layers': 4, 'conv_out': 128, 'kernel_size': 3, 'p': 4.8994094618860434e-05, 'weight_decay': 2.196737582857282e-05, 'fc1_neurons': 120, 'fc2_neurons': 170}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective_with_tricks, n_trials=50)\n",
    "\n",
    "print(\"Najlepsze hiperparametry: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Custom(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1-3): 3 x Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc_last): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "Liczba parametrów modelu: 1249926\n",
      "Epoka [1/10], Strata treningowa: 1.6156976856973435\n",
      "Strata walidacyjna po epoce: 1.3632487053871154\n",
      "Epoka [2/10], Strata treningowa: 1.247723094024923\n",
      "Epoka [3/10], Strata treningowa: 1.0465075536949766\n",
      "Epoka [4/10], Strata treningowa: 0.8950235420183175\n",
      "Strata walidacyjna po epoce: 0.8792721364602446\n",
      "Epoka [5/10], Strata treningowa: 0.7759775990763266\n",
      "Epoka [6/10], Strata treningowa: 0.6816874995420997\n",
      "Epoka [7/10], Strata treningowa: 0.6018214468679287\n",
      "Strata walidacyjna po epoce: 0.7651235457997769\n",
      "Epoka [8/10], Strata treningowa: 0.5290049933870788\n",
      "Epoka [9/10], Strata treningowa: 0.46330891602356244\n",
      "Epoka [10/10], Strata treningowa: 0.39744414352775137\n",
      "Strata walidacyjna po epoce: 0.7746985192916822\n",
      "\n",
      "Wynik dokładności dla mojego modelu dla danych treningowych: 0.7040555555555555\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1000 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "test_images_all = []\n",
    "test_labels_all = []\n",
    "\n",
    "for images, labels in testloader:\n",
    "    test_images_all.append(images)\n",
    "    test_labels_all.extend(labels)\n",
    "    \n",
    "    if len(test_labels_all) >= 30:\n",
    "        break\n",
    "\n",
    "test_images = torch.cat(test_images_all)[:30]\n",
    "test_labels = torch.tensor(test_labels_all[:30])\n",
    "\n",
    "indices = random.sample(range(len(test_images)), 30)\n",
    "selected_images = test_images[indices]\n",
    "selected_labels = test_labels[indices]\n",
    "\n",
    "best_layers = [\n",
    "    {\"entry\": 3, \"out\": 128, \"kernel_size\": 5}\n",
    "]\n",
    "for _ in range(4 - 1):\n",
    "    best_layers.append({\"entry\": 128, \"out\": 128, \"kernel_size\": 5})\n",
    "\n",
    "model = custom_net(lerning_late=0.00013353402447959808, layers=best_layers, num_epochs=10)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(selected_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "fig, axes = plt.subplots(5, 6, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "for idx, (img, true_label, pred_label) in enumerate(zip(selected_images, selected_labels, predicted)):\n",
    "    img = img / 2 + 0.5\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(f'True: {classes[true_label]} \\nPred: {classes[pred_label]}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
